{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a6b3df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be7c90bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"test_f.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ead3be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop(columns=[\"label\"])\n",
    "y=df[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8630f5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta=pd.read_csv(\"meta_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94180c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_m=df_meta.drop(columns=[\"label\"])\n",
    "y_m=df_meta[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f81a32aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(52071, 30)\n"
     ]
    }
   ],
   "source": [
    "print(X_m.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eeaf6335",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34d1bca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb=joblib.load(\"xgb.pkl\")\n",
    "lgb=joblib.load(\"lgb.pkl\")\n",
    "lg=joblib.load(\"lg.pkl\")\n",
    "#svm=joblib.load(\"svm.pkl\")\n",
    "meta_model=joblib.load(\"meta_model.pkl\")\n",
    "scaler_meta=joblib.load(\"scaler_meta.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "302ee471",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_m=scaler_meta.transform(X_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18c60934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predicted probabilities from each model\n",
    "proba_meta = meta_model.predict_proba(X_m)\n",
    "proba_xgb = xgb.predict_proba(X)\n",
    "proba_lgb = lgb.predict_proba(X)\n",
    "proba_lg = lg.predict_proba(X)\n",
    "#proba_svm = svm.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8fad4469",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from itertools import product\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6ce23005",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_meta=-18\n",
    "w_xgb=-18\n",
    "w_lgb=-9\n",
    "w_lg=34\n",
    "#w_svm=1\n",
    "total_w=-18-18-9+34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2faedf7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7542201993432045\n"
     ]
    }
   ],
   "source": [
    "final_proba = (\n",
    "        w_meta * proba_meta +\n",
    "        w_xgb * proba_xgb +\n",
    "        w_lgb * proba_lgb +\n",
    "        w_lg * proba_lg\n",
    "    ) / total_w\n",
    "\n",
    "preds = np.argmax(final_proba, axis=1)\n",
    "acc = accuracy_score(y, preds)\n",
    "print(acc)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5b8767d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy reached 72.43% with weights: meta=1, xgb=1, lgb=1, lg=1\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy reached {acc*100:.2f}% with weights: meta={w_meta}, xgb={w_xgb}, lgb={w_lgb}, lg={w_lg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9b212f69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7243187186725817\n"
     ]
    }
   ],
   "source": [
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5f3af434",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_acc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Final results\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mbest_acc\u001b[49m < \u001b[32m0.90\u001b[39m:\n\u001b[32m      3\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNo combination reached 90%. Best = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_acc*\u001b[32m100\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m% with weights \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_weights\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mNameError\u001b[39m: name 'best_acc' is not defined"
     ]
    }
   ],
   "source": [
    "# Final results\n",
    "if best_acc < 0.90:\n",
    "    print(f\"No combination reached 90%. Best = {best_acc*100:.2f}% with weights {best_weights}\")\n",
    "else:\n",
    "    print(f\"Final best weights: {best_weights}, Accuracy: {best_acc*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4171c195",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c28b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions_comb = final_proba\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a64d88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['predictions_comb.pkl']"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#joblib.dump(predictions_comb,\"predictions_comb.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0fad0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hybrid_ensemble_pred=np.argmax(final_proba, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5daa828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hybrid_ensemble_pred.pkl']"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#joblib.dump(hybrid_ensemble_pred,\"hybrid_ensemble_pred.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5f16df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b8f47e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid ensemble accuracy: 0.8772\n"
     ]
    }
   ],
   "source": [
    "#acc = accuracy_score(y, hybrid_ensemble_pred)\n",
    "#print(\"Hybrid ensemble accuracy:\", acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
